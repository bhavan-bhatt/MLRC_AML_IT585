{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please run the following command and add it to your startup script: \n",
      " export PYTHONPATH=$PYTHONPATH:/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/summ_eval\n",
      "loading spacy\n"
     ]
    }
   ],
   "source": [
    "from summ_eval.chrfpp_metric import ChrfppMetric\n",
    "from summ_eval.cider_metric import CiderMetric\n",
    "from summ_eval.syntactic_metric import SyntacticMetric\n",
    "from summ_eval.data_stats_metric import DataStatsMetric\n",
    "from summ_eval.s3_metric import S3Metric\n",
    "from summ_eval.meteor_metric import MeteorMetric\n",
    "from summ_eval.supert_metric import SupertMetric\n",
    "from summ_eval.blanc_metric import BlancMetric\n",
    "from summ_eval.summa_qa_metric import SummaQAMetric\n",
    "from summ_eval.sentence_movers_metric import SentenceMoversMetric\n",
    "from summ_eval.mover_score_metric import MoverScoreMetric\n",
    "from summ_eval.rouge_we_metric import RougeWeMetric\n",
    "from summ_eval.rouge_metric import RougeMetric\n",
    "from enum import EnumMeta\n",
    "from importlib import import_module\n",
    "import os\n",
    "from re import L\n",
    "from typing import Dict, List, Tuple, Union\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "from nltk import tokenize\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction, corpus_bleu\n",
    "import matplotlib.pyplot as plt\n",
    "from bert_score import BERTScorer\n",
    "import transformers\n",
    "import logging\n",
    "import json\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summ_eval.chrfpp_metric import ChrfppMetric\n",
    "from summ_eval.cider_metric import CiderMetric\n",
    "from summ_eval.syntactic_metric import SyntacticMetric\n",
    "from summ_eval.data_stats_metric import DataStatsMetric\n",
    "from summ_eval.s3_metric import S3Metric\n",
    "from summ_eval.meteor_metric import MeteorMetric\n",
    "from summ_eval.supert_metric import SupertMetric\n",
    "from summ_eval.blanc_metric import BlancMetric\n",
    "from summ_eval.summa_qa_metric import SummaQAMetric\n",
    "from summ_eval.sentence_movers_metric import SentenceMoversMetric\n",
    "from summ_eval.mover_score_metric import MoverScoreMetric\n",
    "from summ_eval.rouge_we_metric import RougeWeMetric\n",
    "from summ_eval.rouge_metric import RougeMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summ_eval.data_stats_metric import DataStatsMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summ_eval.syntactic_metric import SyntacticMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summ_eval.rouge_metric import RougeMetric\n",
    "from summ_eval.rouge_we_metric import RougeWeMetric\n",
    "from summ_eval.mover_score_metric import MoverScoreMetric\n",
    "from summ_eval.blanc_metric import BlancMetric\n",
    "from summ_eval.supert_metric import SupertMetric\n",
    "from summ_eval.blanc_metric import BlancMetric\n",
    "from summ_eval.meteor_metric import MeteorMetric\n",
    "from summ_eval.data_stats_metric import DataStatsMetric\n",
    "from summ_eval.chrfpp_metric import ChrfppMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please run the following command and add it to your startup script: \n",
      " export PYTHONPATH=$PYTHONPATH:/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/summ_eval\n",
      "Compiling scoreline models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:There is less than 2GB of available memory.\n",
      "Will try with limiting Meteor to 1GB of memory but this might cause issues.\n",
      "If you have problems using Meteor, then you can try to lower the `mem` variable in meteor.py\n",
      "calculate score:   0%|                                                       | 0/10 [00:00<?, ?it/s]/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "calculate score:  10%|████▌                                         | 1/10 [03:28<31:13, 208.16s/it]/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "calculate score:  20%|█████████▏                                    | 2/10 [07:11<28:56, 217.11s/it]/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "calculate score:  30%|█████████████▊                                | 3/10 [10:43<25:04, 214.93s/it]/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "calculate score:  40%|██████████████████▍                           | 4/10 [14:26<21:48, 218.12s/it]/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "calculate score:  50%|███████████████████████                       | 5/10 [18:44<19:21, 232.36s/it]/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "calculate score:  60%|███████████████████████████▌                  | 6/10 [23:00<16:01, 240.49s/it]/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "calculate score:  70%|████████████████████████████████▏             | 7/10 [27:36<12:36, 252.02s/it]/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "calculate score:  80%|████████████████████████████████████▊         | 8/10 [32:47<08:11, 245.89s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 693\u001b[0m\n\u001b[1;32m    688\u001b[0m                 print_reslut(splited_score[metrics], control_factor,\n\u001b[1;32m    689\u001b[0m                              x_factor, metrics, model_name, dataset_name, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 693\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 681\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    678\u001b[0m splited_data \u001b[38;5;241m=\u001b[39m split_data_shuffle(\n\u001b[1;32m    679\u001b[0m     statistics_data, data, control_factor)\n\u001b[1;32m    680\u001b[0m splited_data \u001b[38;5;241m=\u001b[39m shuffle_data(splited_data)\n\u001b[0;32m--> 681\u001b[0m splited_score \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_score_splited\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplited_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_factor \u001b[38;5;129;01min\u001b[39;00m factor_list:\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x_factor \u001b[38;5;241m==\u001b[39m control_factor:\n",
      "Cell \u001b[0;32mIn[1], line 101\u001b[0m, in \u001b[0;36mcalculate_score_splited\u001b[0;34m(data, mode)\u001b[0m\n\u001b[1;32m     98\u001b[0m     mode \u001b[38;5;241m=\u001b[39m [mode]\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m--> 101\u001b[0m     temp_score_list \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_score_splited_cpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m temp_score_list\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    103\u001b[0m         score_list[k] \u001b[38;5;241m=\u001b[39m v\n",
      "Cell \u001b[0;32mIn[1], line 158\u001b[0m, in \u001b[0;36mcalculate_score_splited_cpu\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    138\u001b[0m summary_lens_list \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m5\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m splited_data]\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# score_dict = rouge_model.evaluate_batch(\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# summaries=summary_list, references=reference_list, aggregate=False)\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# for i, score in enumerate(score_dict):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m#                 splited_score_list[k].append(\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m#                     (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m score_dict \u001b[38;5;241m=\u001b[39m \u001b[43mrougewe_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43msummaries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msummary_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggregate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, score \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(score_dict):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m score\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniforge3/envs/exp/lib/python3.10/site-packages/summ_eval/rouge_we_metric.py:60\u001b[0m, in \u001b[0;36mRougeWeMetric.evaluate_batch\u001b[0;34m(self, summaries, references, aggregate)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, summaries, references, aggregate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m     p \u001b[38;5;241m=\u001b[39m Pool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_workers)\n\u001b[0;32m---> 60\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_example\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msummaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     p\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m aggregate:\n",
      "File \u001b[0;32m~/miniforge3/envs/exp/lib/python3.10/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/exp/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/exp/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/exp/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniforge3/envs/exp/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict, List, Tuple, Union\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "from nltk import tokenize\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import matplotlib.pyplot as plt\n",
    "from bert_score import BERTScorer\n",
    "import transformers\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "from summ_eval.rouge_metric import RougeMetric\n",
    "from summ_eval.rouge_we_metric import RougeWeMetric\n",
    "from summ_eval.mover_score_metric import MoverScoreMetric\n",
    "from summ_eval.blanc_metric import BlancMetric\n",
    "from summ_eval.supert_metric import SupertMetric\n",
    "from summ_eval.blanc_metric import BlancMetric\n",
    "from summ_eval.meteor_metric import MeteorMetric\n",
    "from summ_eval.data_stats_metric import DataStatsMetric\n",
    "from summ_eval.chrfpp_metric import ChrfppMetric\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "log_level = logging.ERROR\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "\n",
    "\n",
    "metrics_list = ['rouge-1', 'rouge-2', 'rouge-l', 'bleu', 'bertscore']\n",
    "# metrics_list = ['rouge-1','rouge-2','rouge-l','bleu']\n",
    "factor_list = ['article', 'generation', 'groundtruth']\n",
    "\n",
    "\n",
    "def get_groundtruth(file_path: str) -> List[List[str]]:\n",
    "    data = list()\n",
    "    raw_data = pd.read_csv(file_path)\n",
    "    raw_data = raw_data.values.tolist()\n",
    "    for i, item in enumerate(raw_data):\n",
    "        if len(item) == 2:\n",
    "            item = [i] + item\n",
    "        if len(item[1].split(' ')) < 10 or len(item[2].split(' ')) < 10:\n",
    "            continue\n",
    "        data.append(item)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_summarization(file_path: str) -> List[str]:\n",
    "    data = list()\n",
    "    with open(file_path, mode='r', encoding='utf8') as fp:\n",
    "        for line in fp.readlines():\n",
    "            data.append('\\n'.join(tokenize.sent_tokenize(line.strip())))\n",
    "    return data\n",
    "\n",
    "\n",
    "def combine_data(groundtruth_data: List[List[Union[str, int, List[str]]]], generated_data: List[str]) -> Tuple[List[Dict[str, Union[str, int]]], Dict[str, List[int]]]:\n",
    "    data = list()\n",
    "    error_count = 0\n",
    "    for i, item in enumerate(groundtruth_data):\n",
    "        if len(item) == 3:\n",
    "            item.append(len(item[1].replace('\\n', ' ').split(' ')))\n",
    "            item.append(len(item[2].replace('\\n', ' ').split(' ')))\n",
    "            item.append(list())\n",
    "            item.append(list())\n",
    "        item[5].append(len(generated_data[i].replace('\\n', ' ').split(' ')))\n",
    "        item[6].append(generated_data[i])\n",
    "        data.append(item)\n",
    "    return data\n",
    "\n",
    "\n",
    "def calcualte_length(groundtruth_data: List[List[str]], data) -> Dict[str, List[int]]:\n",
    "    statistics_data = {'article_lens': list(\n",
    "    ), 'groundtruth_lens': list(), 'generation_lens': list()}\n",
    "    for i, item in enumerate(groundtruth_data):\n",
    "        item_data = {'id': item[0], 'article': item[1], 'groundtruth': item[2]}\n",
    "        item_data['article_lens'] = len(\n",
    "            item_data['article'].replace('\\n', ' ').split(' '))\n",
    "        item_data['groundtruth_lens'] = len(\n",
    "            item_data['groundtruth'].replace('\\n', ' ').split(' '))\n",
    "        item_data['generation_lens'] = np.mean(data[i][5])\n",
    "        data[i][5] = np.mean(data[i][5])\n",
    "\n",
    "        statistics_data['article_lens'].append(item_data['article_lens'])\n",
    "        statistics_data['groundtruth_lens'].append(\n",
    "            item_data['groundtruth_lens'])\n",
    "        statistics_data['generation_lens'].append(item_data['generation_lens'])\n",
    "    return statistics_data\n",
    "\n",
    "\n",
    "def calculate_score_splited(data, mode):\n",
    "    score_list = dict()\n",
    "\n",
    "    if mode == 'all':\n",
    "        mode = ['cpu', 'gpu']\n",
    "    else:\n",
    "        mode = [mode]\n",
    "\n",
    "    if 'cpu' in mode:\n",
    "        temp_score_list = calculate_score_splited_cpu(data)\n",
    "        for k, v in temp_score_list.items():\n",
    "            score_list[k] = v\n",
    "\n",
    "    if 'gpu' in mode:\n",
    "        temp_score_list = calculate_score_splited_gpu(data)\n",
    "        for k, v in temp_score_list.items():\n",
    "            score_list[k] = v\n",
    "\n",
    "    return score_list\n",
    "\n",
    "\n",
    "def calculate_score_splited_cpu(data):\n",
    "    total_item = 0\n",
    "    for it in data:\n",
    "        total_item += len(it)\n",
    "    total_item = total_item\n",
    "\n",
    "    chencherry = SmoothingFunction()\n",
    "\n",
    "    # rouge_model = RougeMetric()\n",
    "    rougewe_model = RougeWeMetric()\n",
    "    meteor_model = MeteorMetric()\n",
    "    datastats_model = DataStatsMetric()\n",
    "    chrfpp_model = ChrfppMetric()\n",
    "\n",
    "    score_list = dict()\n",
    "    for splited_data in tqdm.tqdm(data, desc='calculate score', ncols=100):\n",
    "        splited_score_list = dict()\n",
    "\n",
    "        article_list = [item[1].replace('\\n', ' ') for item in splited_data]\n",
    "        reference_list = [item[2].replace('\\n', ' ') for item in splited_data]\n",
    "        summary_list = [item[-1][0].replace('\\n', ' ')\n",
    "                        for item in splited_data]\n",
    "\n",
    "        article_lens_list = [item[3] for item in splited_data]\n",
    "        reference_lens_list = [item[4] for item in splited_data]\n",
    "        summary_lens_list = [item[5] for item in splited_data]\n",
    "\n",
    "        # score_dict = rouge_model.evaluate_batch(\n",
    "            # summaries=summary_list, references=reference_list, aggregate=False)\n",
    "        # for i, score in enumerate(score_dict):\n",
    "        #     try:\n",
    "        #         for k, v in score['rouge'].items():\n",
    "        #             if k.endswith('_f_score'):\n",
    "        #                 if k not in splited_score_list:\n",
    "        #                     splited_score_list[k] = list()\n",
    "        #                 splited_score_list[k].append(\n",
    "        #                     (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "        #     except:\n",
    "        #         for k, v in score.items():\n",
    "        #             if k.endswith('_f_score'):\n",
    "        #                 if k not in splited_score_list:\n",
    "        #                     splited_score_list[k] = list()\n",
    "        #                 splited_score_list[k].append(\n",
    "        #                     (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "\n",
    "        score_dict = rougewe_model.evaluate_batch(\n",
    "            summaries=summary_list, references=reference_list, aggregate=False)\n",
    "        for i, score in enumerate(score_dict):\n",
    "            for k, v in score.items():\n",
    "                if k.endswith('_f'):\n",
    "                    if k not in splited_score_list:\n",
    "                        splited_score_list[k] = list()\n",
    "                    splited_score_list[k].append(\n",
    "                        (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "\n",
    "        score_dict = meteor_model.evaluate_batch(\n",
    "            summaries=summary_list, references=reference_list, aggregate=False)\n",
    "        for i, score in enumerate(score_dict):\n",
    "            for k, v in score.items():\n",
    "                if k not in splited_score_list:\n",
    "                    splited_score_list[k] = list()\n",
    "                splited_score_list[k].append(\n",
    "                    (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "\n",
    "        score_dict = datastats_model.evaluate_batch(\n",
    "            summaries=summary_list, input_texts=article_list, aggregate=False)\n",
    "        for i, score in enumerate(score_dict):\n",
    "            for k, v in score.items():\n",
    "                if k not in splited_score_list:\n",
    "                    splited_score_list[k] = list()\n",
    "                splited_score_list[k].append(\n",
    "                    (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "\n",
    "        score_dict = chrfpp_model.evaluate_batch(\n",
    "            summaries=summary_list, references=reference_list, aggregate=False)\n",
    "        for i, score in enumerate(score_dict):\n",
    "            for k, v in score.items():\n",
    "                if k not in splited_score_list:\n",
    "                    splited_score_list[k] = list()\n",
    "                splited_score_list[k].append(\n",
    "                    (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "\n",
    "        for i, item in enumerate(splited_data):\n",
    "            groundtruth = item[2]\n",
    "            summary = item[-1][0]\n",
    "            bleu = sentence_bleu(references=[groundtruth.replace('\\n', ' ').split(\n",
    "            )], hypothesis=summary.replace('\\n', ' ').split(), smoothing_function=chencherry.method1)\n",
    "            if 'bleu' not in splited_score_list:\n",
    "                splited_score_list['bleu'] = list()\n",
    "            splited_score_list['bleu'].append(\n",
    "                (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], bleu*100))\n",
    "\n",
    "        for metrics, v in splited_score_list.items():\n",
    "            if metrics not in score_list:\n",
    "                score_list[metrics] = list()\n",
    "            score_list[metrics].append(v)\n",
    "    return score_list\n",
    "\n",
    "\n",
    "def calculate_score_splited_gpu(data):\n",
    "    total_item = 0\n",
    "    for it in data:\n",
    "        total_item += len(it)\n",
    "    total_item = total_item\n",
    "\n",
    "    moverscore_model = MoverScoreMetric()\n",
    "    Bertscore_model = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
    "    blanc_model = BlancMetric(inference_batch_size=64, finetune_batch_size=12)\n",
    "    supert_model = SupertMetric()\n",
    "\n",
    "    score_list = dict()\n",
    "    for splited_data in tqdm.tqdm(data, desc='calculate score', ncols=100):\n",
    "        splited_score_list = dict()\n",
    "\n",
    "        article_list = [item[1].replace('\\n', ' ') for item in splited_data]\n",
    "        reference_list = [item[2].replace('\\n', ' ') for item in splited_data]\n",
    "        summary_list = [item[-1][0].replace('\\n', ' ')\n",
    "                        for item in splited_data]\n",
    "\n",
    "        article_lens_list = [item[3] for item in splited_data]\n",
    "        reference_lens_list = [item[4] for item in splited_data]\n",
    "        summary_lens_list = [item[5] for item in splited_data]\n",
    "\n",
    "        score_dict = moverscore_model.evaluate_batch(\n",
    "            summaries=summary_list, references=reference_list, aggregate=False)\n",
    "        for i, score in enumerate(score_dict):\n",
    "            for k, v in score.items():\n",
    "                if k not in splited_score_list:\n",
    "                    splited_score_list[k] = list()\n",
    "                splited_score_list[k].append(\n",
    "                    (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "\n",
    "        _, _, bert_score = Bertscore_model.score(\n",
    "            cands=summary_list, refs=reference_list, batch_size=12)\n",
    "        if 'bert_score_f1' not in splited_score_list:\n",
    "            splited_score_list['bert_score_f1'] = list()\n",
    "        for i, score in enumerate(bert_score.numpy().tolist()):\n",
    "            splited_score_list['bert_score_f1'].append(\n",
    "                (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], score*100))\n",
    "\n",
    "        # score_dict = summaqa_model.evaluate_batch(summaries = summary_list, input_texts = article_list, aggregate=False)\n",
    "        # for i, score in enumerate(score_dict):\n",
    "        #     for k,v in score.items():\n",
    "        #         if k not in splited_score_list:\n",
    "        #             splited_score_list[k] = list()\n",
    "        #         splited_score_list[k].append((article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100 ))\n",
    "\n",
    "        score_dict = blanc_model.evaluate_batch(\n",
    "            summaries=summary_list, input_texts=article_list, aggregate=False, show_progress_bar=False)\n",
    "        for i, score in enumerate(score_dict):\n",
    "            for k, v in score.items():\n",
    "                if k not in splited_score_list:\n",
    "                    splited_score_list[k] = list()\n",
    "                splited_score_list[k].append(\n",
    "                    (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "\n",
    "        score_dict = supert_model.evaluate_batch(\n",
    "            summaries=summary_list, input_texts=article_list, aggregate=False)\n",
    "        for i, score in enumerate(score_dict):\n",
    "            for k, v in score.items():\n",
    "                if k not in splited_score_list:\n",
    "                    splited_score_list[k] = list()\n",
    "                try:\n",
    "                    splited_score_list[k].append(\n",
    "                        (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "                except:\n",
    "                    splited_score_list[k].append(\n",
    "                        (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], 0))\n",
    "\n",
    "        for metrics, v in splited_score_list.items():\n",
    "            if metrics not in score_list:\n",
    "                score_list[metrics] = list()\n",
    "            score_list[metrics].append(v)\n",
    "\n",
    "    return score_list\n",
    "\n",
    "\n",
    "def calculate_score(data, model_name, mode):\n",
    "    score_list = dict()\n",
    "\n",
    "    if mode == 'all':\n",
    "        mode = ['cpu', 'gpu']\n",
    "    else:\n",
    "        mode = [mode]\n",
    "\n",
    "    if 'cpu' in mode:\n",
    "        temp_score_list = calculate_score_cpu(data, model_name)\n",
    "        for k, v in temp_score_list.items():\n",
    "            score_list[k] = v\n",
    "\n",
    "    if 'gpu' in mode:\n",
    "        temp_score_list = calculate_score_gpu(data, model_name)\n",
    "        for k, v in temp_score_list.items():\n",
    "            score_list[k] = v\n",
    "\n",
    "    return score_list\n",
    "\n",
    "\n",
    "def calculate_score_cpu(data, model_name):\n",
    "    score_list = dict()\n",
    "\n",
    "    article_list = [item[1].replace('\\n', ' ') for item in data]\n",
    "    reference_list = [item[2].replace('\\n', ' ') for item in data]\n",
    "    summary_list = [item[-1][0].replace('\\n', ' ') for item in data]\n",
    "\n",
    "    article_lens_list = [item[3] for item in data]\n",
    "    reference_lens_list = [item[4] for item in data]\n",
    "    summary_lens_list = [item[5] for item in data]\n",
    "\n",
    "    datastats_model = DataStatsMetric()\n",
    "\n",
    "    print('datasets Start')\n",
    "    score_dict = datastats_model.evaluate_batch(\n",
    "        summaries=summary_list, input_texts=article_list, aggregate=False, show_progress_bar=True)\n",
    "\n",
    "    if model_name == 'groundtruth':\n",
    "        for i, score in enumerate(score_dict):\n",
    "            for k, v in score.items():\n",
    "                if k not in score_list:\n",
    "                    score_list[k] = list()\n",
    "                score_list[k].append(\n",
    "                    (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "\n",
    "        return score_list\n",
    "\n",
    "    chencherry = SmoothingFunction()\n",
    "    rouge_model = RougeMetric()\n",
    "    rougewe_model = RougeWeMetric()\n",
    "    meteor_model = MeteorMetric()\n",
    "    chrfpp_model = ChrfppMetric()\n",
    "\n",
    "    print('Rouge Start')\n",
    "    score_dict = rouge_model.evaluate_batch(\n",
    "        summaries=summary_list, references=reference_list, aggregate=False, show_progress_bar=True)\n",
    "    for i, score in enumerate(score_dict):\n",
    "        try:\n",
    "            for k, v in score['rouge'].items():\n",
    "                if k.endswith('_f_score'):\n",
    "                    if k not in score_list:\n",
    "                        score_list[k] = list()\n",
    "                    score_list[k].append(\n",
    "                        (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "        except:\n",
    "            for k, v in score.items():\n",
    "                if k.endswith('_f_score'):\n",
    "                    if k not in score_list:\n",
    "                        score_list[k] = list()\n",
    "                    score_list[k].append(\n",
    "                        (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "\n",
    "    print('RougeWe Start')\n",
    "    score_dict = rougewe_model.evaluate_batch(\n",
    "        summaries=summary_list, references=reference_list, aggregate=False, show_progress_bar=True)\n",
    "    for i, score in enumerate(score_dict):\n",
    "        for k, v in score.items():\n",
    "            if k.endswith('_f'):\n",
    "                if k not in score_list:\n",
    "                    score_list[k] = list()\n",
    "                score_list[k].append(\n",
    "                    (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "\n",
    "    print('meteor Start')\n",
    "    score_dict = meteor_model.evaluate_batch(\n",
    "        summaries=summary_list, references=reference_list, aggregate=False, show_progress_bar=True)\n",
    "    for i, score in enumerate(score_dict):\n",
    "        for k, v in score.items():\n",
    "            if k not in score_list:\n",
    "                score_list[k] = list()\n",
    "            score_list[k].append(\n",
    "                (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "\n",
    "    print(\"chrfpp starts\")\n",
    "    score_dict = chrfpp_model.evaluate_batch(\n",
    "        summaries=summary_list, references=reference_list, aggregate=False, show_progress_bar=True)\n",
    "    for i, score in enumerate(score_dict):\n",
    "        for k, v in score.items():\n",
    "            if k not in score_list:\n",
    "                score_list[k] = list()\n",
    "            score_list[k].append(\n",
    "                (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "\n",
    "    print('BLEU Start')\n",
    "    for _, item in enumerate(tqdm.tqdm(data, ncols=True, desc='Calculate BLEU')):\n",
    "        groundtruth = item[2]\n",
    "        summary = item[-1][0]\n",
    "        bleu = sentence_bleu(references=[groundtruth.replace('\\n', ' ').split(\n",
    "        )], hypothesis=summary.replace('\\n', ' ').split(), smoothing_function=chencherry.method1)\n",
    "        if 'bleu' not in score_list:\n",
    "            score_list['bleu'] = list()\n",
    "        score_list['bleu'].append((item[3], item[4], item[5], bleu*100))\n",
    "\n",
    "    for i, score in enumerate(score_dict):\n",
    "        for k, v in score.items():\n",
    "            if k not in score_list:\n",
    "                score_list[k] = list()\n",
    "            score_list[k].append(\n",
    "                (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "\n",
    "    return score_list\n",
    "\n",
    "\n",
    "def calculate_score_gpu(data, model_name):\n",
    "    score_list = dict()\n",
    "\n",
    "    article_list = [item[1].replace('\\n', ' ') for item in data]\n",
    "    reference_list = [item[2].replace('\\n', ' ') for item in data]\n",
    "    summary_list = [item[-1][0].replace('\\n', ' ') for item in data]\n",
    "\n",
    "    article_lens_list = [item[3] for item in data]\n",
    "    reference_lens_list = [item[4] for item in data]\n",
    "    summary_lens_list = [item[5] for item in data]\n",
    "\n",
    "    # summaqa_model =  SummaQAMetric(max_seq_len=4096, batch_size=4)\n",
    "    blanc_model = BlancMetric(inference_batch_size=64, finetune_batch_size=12)\n",
    "    supert_model = SupertMetric()\n",
    "\n",
    "    print('Supert Start')\n",
    "    score_dict = supert_model.evaluate_batch(\n",
    "        summaries=summary_list, input_texts=article_list, aggregate=False, show_progress_bar=True)\n",
    "    for i, score in enumerate(score_dict):\n",
    "        for k, v in score.items():\n",
    "            if k not in score_list:\n",
    "                score_list[k] = list()\n",
    "            try:\n",
    "                score_list[k].append(\n",
    "                    (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "            except:\n",
    "                score_list[k].append(\n",
    "                    (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], 0))\n",
    "\n",
    "    # print('Summaqa Start')\n",
    "    # score_dict = summaqa_model.evaluate_batch(summaries = summary_list, input_texts = article_list, aggregate=False)\n",
    "    # for i, score in enumerate(score_dict):\n",
    "    #     for k,v in score.items():\n",
    "    #         if k not in score_list:\n",
    "    #             score_list[k] = list()\n",
    "    #         score_list[k].append((article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100 ))\n",
    "\n",
    "    print('Blanc Start')\n",
    "    score_dict = blanc_model.evaluate_batch(\n",
    "        summaries=summary_list, input_texts=article_list, aggregate=False)\n",
    "\n",
    "    if model_name == 'groundtruth':\n",
    "        for i, score in enumerate(score_dict):\n",
    "            for k, v in score.items():\n",
    "                if k not in score_list:\n",
    "                    score_list[k] = list()\n",
    "                score_list[k].append(\n",
    "                    (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "\n",
    "        return score_list\n",
    "\n",
    "    moverscore_model = MoverScoreMetric()\n",
    "    Bertscore_model = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
    "    # summaqa_model =  SummaQAMetric(max_seq_len=4096, batch_size=4)\n",
    "\n",
    "    print('MoverScore Start')\n",
    "    score_dict = moverscore_model.evaluate_batch(\n",
    "        summaries=summary_list, references=reference_list, aggregate=False, show_progress_bar=True)\n",
    "    for i, score in enumerate(score_dict):\n",
    "        for k, v in score.items():\n",
    "            if k not in score_list:\n",
    "                score_list[k] = list()\n",
    "            score_list[k].append(\n",
    "                (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "\n",
    "    print('Bertscore Start')\n",
    "    _, _, bert_score = Bertscore_model.score(\n",
    "        cands=summary_list, refs=reference_list, batch_size=12)\n",
    "    if 'bert_score_f1' not in score_list:\n",
    "        score_list['bert_score_f1'] = list()\n",
    "    for i, score in enumerate(bert_score.numpy().tolist()):\n",
    "        score_list['bert_score_f1'].append(\n",
    "            (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], score*100))\n",
    "\n",
    "    for i, score in enumerate(score_dict):\n",
    "        for k, v in score.items():\n",
    "            if k not in score_list:\n",
    "                score_list[k] = list()\n",
    "            score_list[k].append(\n",
    "                (article_lens_list[i], reference_lens_list[i], summary_lens_list[i], v*100))\n",
    "\n",
    "    return score_list\n",
    "\n",
    "\n",
    "def split_data_shuffle(statistics_data, data, split_base):\n",
    "    split_number = 10\n",
    "    if split_base == 'article':\n",
    "        split_index = 3\n",
    "    elif split_base == 'groundtruth':\n",
    "        split_index = 4\n",
    "    elif split_base == 'generation':\n",
    "        split_index = 5\n",
    "\n",
    "    random.shuffle(data)\n",
    "    sorted_shuffled_item = sorted(data, key=lambda x: x[split_index])\n",
    "    split_count = int(len(sorted_shuffled_item) / split_number)\n",
    "    bucket_data = [[] for _ in range(split_number)]\n",
    "    for j in range(split_number):\n",
    "        bucket_data[j] = [\n",
    "            it for it in sorted_shuffled_item[j*split_count:(j+1)*split_count]]\n",
    "    if split_count * split_number != len(data):\n",
    "        for it in sorted_shuffled_item[split_number*split_count:]:\n",
    "            bucket_data[j].append(it)\n",
    "    return bucket_data\n",
    "\n",
    "\n",
    "def split_data(statistics_data, data, split_base):\n",
    "    splited_data = dict()\n",
    "    for k, score_data in data.items():\n",
    "        split_number = 10\n",
    "        split_index = 0\n",
    "        if split_base == 'article':\n",
    "            split_index = 0\n",
    "        elif split_base == 'groundtruth':\n",
    "            split_index = 1\n",
    "        elif split_base == 'generation':\n",
    "            split_index = 2\n",
    "\n",
    "        random.shuffle(score_data)\n",
    "        sorted_shuffled_item = sorted(score_data, key=lambda x: x[split_index])\n",
    "        split_count = int(len(sorted_shuffled_item) / split_number)\n",
    "        bucket_data = [[] for _ in range(split_number)]\n",
    "        for j in range(split_number):\n",
    "            bucket_data[j] = [\n",
    "                it for it in sorted_shuffled_item[j*split_count:(j+1)*split_count]]\n",
    "        if split_count * split_number != len(score_data):\n",
    "            for it in sorted_shuffled_item[split_number*split_count:]:\n",
    "                bucket_data[j].append(it)\n",
    "        splited_data[k] = bucket_data\n",
    "    return splited_data\n",
    "\n",
    "\n",
    "def shuffle_data(data):\n",
    "    shuffled_data = list()\n",
    "    for splited_data in data:\n",
    "        generation_list = list()\n",
    "        for item in splited_data:\n",
    "            generation_list.append((item[5], item[-1]))\n",
    "        old_generation_list = deepcopy(generation_list)\n",
    "        difference_mark = False\n",
    "        while not difference_mark:\n",
    "            check_mark = True\n",
    "            random.shuffle(generation_list)\n",
    "            for old_generation, generation in zip(old_generation_list, generation_list):\n",
    "                if old_generation == generation:\n",
    "                    check_mark = False\n",
    "                    break\n",
    "            if check_mark:\n",
    "                difference_mark = True\n",
    "        for i, item in enumerate(splited_data):\n",
    "            item[-1] = generation_list[i][1]\n",
    "            item[5] = generation_list[i][0]\n",
    "        shuffled_data.append(splited_data)\n",
    "    return shuffled_data\n",
    "\n",
    "\n",
    "def filter_data(groundtruth_data, data):\n",
    "    filtered_groundtruth_data = list()\n",
    "    filtered_data = list()\n",
    "    for i, item in enumerate(data):\n",
    "        if item[3] < 10 or item[4] < 10 or np.mean(item[5]) < 10:\n",
    "            continue\n",
    "        filtered_groundtruth_data.append(groundtruth_data[i])\n",
    "        filtered_data.append(data[i])\n",
    "    return filtered_groundtruth_data, filtered_data\n",
    "\n",
    "\n",
    "def save_score(bucket_data, control_factor, split_base, metrics, model_name, dataset_name, random=False):\n",
    "    bucket_data_np = np.array(bucket_data, dtype=object)\n",
    "    model_name = model_name.split('/')[-1]\n",
    "    folder = \"./result/{}/{}/{}/data\".format(metrics, model_name, dataset_name)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    file = \"./result/{}/{}/{}/data/{}_{}\".format(\n",
    "        metrics, model_name, dataset_name, control_factor, split_base)\n",
    "    if random == True:\n",
    "        file = file + '_random'\n",
    "    np.save(file, bucket_data_np)\n",
    "\n",
    "\n",
    "def print_reslut(bucket_data, control_factor, split_base, metrics, model_name, dataset_name, random_shuffle=False):\n",
    "    model_name = model_name.split('/')[-1]\n",
    "    split_number = 10\n",
    "    split_index = 0\n",
    "    if split_base == 'article':\n",
    "        split_index = 0\n",
    "    elif split_base == 'groundtruth':\n",
    "        split_index = 1\n",
    "    elif split_base == 'generation':\n",
    "        split_index = 2\n",
    "\n",
    "    for i, item in enumerate(bucket_data):\n",
    "        random.shuffle(item)\n",
    "        sorted_shuffled_item = sorted(item, key=lambda x: x[split_index])\n",
    "        split_count = int(len(sorted_shuffled_item) / split_number)\n",
    "        bucket = [[] for _ in range(split_number)]\n",
    "        for j in range(split_number):\n",
    "            bucket[j] = [it[-1]\n",
    "                         for it in sorted_shuffled_item[j*split_count:(j+1)*split_count]]\n",
    "        if split_count * split_number != len(item):\n",
    "            for it in sorted_shuffled_item[split_number*split_count:]:\n",
    "                bucket[j].append(it[-1])\n",
    "        y = [np.mean(d) for d in bucket]\n",
    "        plt.plot([1/split_number*j for j in range(split_number)], y,\n",
    "                 label='{}% length of {}'.format((i+1)*len(bucket_data), control_factor))\n",
    "    plt.title(\"The performance when controlling {} length\".format(control_factor))\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "    plt.xlabel(\"percent of length of {}\".format(split_base))\n",
    "    folder = \"./result/{}/{}/{}/picture\".format(\n",
    "        metrics, model_name, dataset_name)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    file = \"./result/{}/{}/{}/picture/{}_{}.jpg\".format(\n",
    "        metrics, model_name, dataset_name, control_factor, split_base)\n",
    "    if random_shuffle == True:\n",
    "        file = file.replace('.jpg', '_random.jpg')\n",
    "    plt.savefig(file, bbox_inches='tight')\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # shuffle=False\n",
    "\n",
    "    random.seed(42)\n",
    "    # dataset_name = ''\n",
    "    # for model_name in ['facebook/bart-base', 't5-base', 'allenai/led-base-16384']:\n",
    "\n",
    "    dataset_name = 'cnn_dailymail'\n",
    "    model_name = 'facebook/bart-base'\n",
    "    mode = 'cpu'\n",
    "\n",
    "    # dataset_name = 'wikihowAll'\n",
    "    # model_name = 'groundtruth'\n",
    "    # mode = 'cpu'\n",
    "\n",
    "    groudtruth_file = './data/{}/test.csv'.format(dataset_name)\n",
    "    groundtruth_data = get_groundtruth(groudtruth_file)\n",
    "    if model_name == 'groundtruth':\n",
    "        summary_data = [item[2] for item in groundtruth_data]\n",
    "        data = combine_data(groundtruth_data, summary_data)\n",
    "    else:\n",
    "        for random_seed in [0]:\n",
    "            generated_file = './model/{}/{}/{}/generated_predictions.txt'.format(\n",
    "                dataset_name, model_name, random_seed)\n",
    "            summary_data = get_summarization(generated_file)\n",
    "            data = combine_data(groundtruth_data, summary_data)\n",
    "        if dataset_name == 'corpus-webis-tldr-17':\n",
    "            groundtruth_data, data = filter_data(groundtruth_data, data)\n",
    "    statistics_data = calcualte_length(groundtruth_data, data)\n",
    "\n",
    "    # score = calculate_score(data, model_name, mode)\n",
    "    # for control_factor in factor_list:\n",
    "    #     splited_score = split_data(statistics_data, score, control_factor)\n",
    "    #     for x_factor in factor_list:\n",
    "    #         if x_factor == control_factor:\n",
    "    #             continue\n",
    "    #         for metrics in tqdm.tqdm(list(splited_score.keys()), desc='create picture', ncols=100):\n",
    "    #             save_score(splited_score[metrics], control_factor,\n",
    "    #                        x_factor, metrics, model_name, dataset_name)\n",
    "    #             print_reslut(splited_score[metrics], control_factor,\n",
    "    #                          x_factor, metrics, model_name, dataset_name)\n",
    "\n",
    "    for control_factor in factor_list:\n",
    "        splited_data = split_data_shuffle(\n",
    "            statistics_data, data, control_factor)\n",
    "        splited_data = shuffle_data(splited_data)\n",
    "        splited_score = calculate_score_splited(splited_data, mode)\n",
    "        for x_factor in factor_list:\n",
    "            if x_factor == control_factor:\n",
    "                continue\n",
    "            for metrics in tqdm.tqdm(list(splited_score.keys()), desc='create picture', ncols=100):\n",
    "                save_score(splited_score[metrics], control_factor,\n",
    "                           x_factor, metrics, model_name, dataset_name, True)\n",
    "                print_reslut(splited_score[metrics], control_factor,\n",
    "                             x_factor, metrics, model_name, dataset_name, True)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrouge import Rouge155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rouge155(rouge_dir='/Users/bhavanbhatt/miniforge3/envs/exp/lib/python3.10/site-packages/summ_eval/ROUGE-1.5.5', rouge_args=None, log_level=log_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
